# pytorch-ppo

Implementation of PPO in `pytorch`.

(Mostly) from scratch, but borrows nontrivially from [pytorch-ppo](https://github.com/tpbarron/pytorch-ppo) and [openai/baselines](https://github.com/openai/baselines)

### Requirements

Requires `pytorch` +  `openai/gym` w/ `mujoco`.